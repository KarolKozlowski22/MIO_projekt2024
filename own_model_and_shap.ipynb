{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import shap\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m872s\u001b[0m 640ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_8888\\1716926224.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data_cleaned['Predicted_Sentiment'] = predicted_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content Predicted_Sentiment\n",
      "0  sure tune watch donald trump late night david ...             Neutral\n",
      "1  donald trump appearing view tomorrow morning d...             Neutral\n",
      "2  donald trump reads top ten financial tips late...             Neutral\n",
      "3  new blog post celebrity apprentice finale less...            Negative\n",
      "4  persona never wallflower rather build walls cl...             Neutral\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model_big.h5')\n",
    "new_data = pd.read_csv('cleaned_trump_tweets.csv')\n",
    "new_data_cleaned = new_data.dropna(subset=['content'])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=500, split=' ') \n",
    "tokenizer.fit_on_texts(new_data_cleaned['content'].values)\n",
    "X_new = tokenizer.texts_to_sequences(new_data_cleaned['content'].values)\n",
    "X_new = pad_sequences(X_new, maxlen=model.input_shape[1])\n",
    "\n",
    "predictions = model.predict(X_new)\n",
    "sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
    "predicted_labels = [sentiment_labels[np.argmax(pred)] for pred in predictions]\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "new_data_cleaned['Predicted_Sentiment'] = predicted_labels\n",
    "\n",
    "new_data_cleaned.to_csv('predicted_sentiments.csv', index=False)\n",
    "print(new_data_cleaned[['content', 'Predicted_Sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.76      0.86      0.81      1528\n",
      "     Neutral       0.88      0.90      0.89      4268\n",
      "    Positive       0.96      0.86      0.90      2855\n",
      "\n",
      "    accuracy                           0.88      8651\n",
      "   macro avg       0.87      0.87      0.87      8651\n",
      "weighted avg       0.88      0.88      0.88      8651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=new_data_cleaned['content']\n",
    "y=new_data_cleaned['Predicted_Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test_tfidf)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_test_sample \u001b[38;5;241m=\u001b[39m \u001b[43mX_test_tfidf\u001b[49m[:\u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m      2\u001b[0m X_test_sample_dense \u001b[38;5;241m=\u001b[39m X_test_sample\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m      4\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mTreeExplainer(clf)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "X_test_sample = X_test_tfidf[:10]\n",
    "X_test_sample_dense = X_test_sample.toarray()\n",
    "\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "\n",
    "shap_values = explainer.shap_values(X_test_sample_dense)\n",
    "\n",
    "shap.initjs()\n",
    "shap.summary_plot(shap_values, X_test_tfidf, feature_names=vectorizer.get_feature_names_out())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
